{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Weak Lensing Testing Notebook**\n",
    "\n",
    "Notebook for testing of weak-lensing computed profiles for galaxy clusters in DES. The following lines can be used to analyze the structure of the dataset.\n",
    "```\n",
    "cd /project/projectdirs/des/www/y3_cats/\n",
    "h5ls -f -r --follow-symlinks Y3_mastercat_03_31_20.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Initialize Notebook and Load Catalog**\n",
    "\n",
    "Initializes the notebook and its package dependencies. Loads Y3 master catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import treecorr\n",
    "import h5py\n",
    "import kmeans_radec\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import astropy.units as u\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from astropy.coordinates import SkyCoord\n",
    "import sys\n",
    "\n",
    "cosmo = FlatLambdaCDM(H0=70, Om0=0.3)\n",
    "\n",
    "sns.set(style='ticks')\n",
    "\n",
    "%config IPCompleter.greedy = True\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "def progress_bar(cur_val, final_val):\n",
    "    \"\"\" \n",
    "    Function to keep track of progress during computations by displaying\n",
    "    a progress bar\n",
    "\n",
    "    Parameters:\n",
    "    cur_val (int/float): current iteration/value calculation is on\n",
    "    final_val (int/float): final iteration/value that calculation will take\n",
    "    \"\"\"\n",
    "\n",
    "    bar_length = 20\n",
    "    percent = float(cur_val) / final_val\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    sys.stdout.write(\"\\rProgress: [{0}]\"\n",
    "                     \" {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "cat_str = '/project/projectdirs/des/www/y3_cats/Y3_mastercat_03_31_20.h5'\n",
    "\n",
    "f = h5py.File(cat_str,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red_magic_str = '/project/projectdirs/des/www/y3_cats/y3_gold_2.2.1_wide_sofcol_run_redmapper_v0.5.1_redmagic_12_3_19.h5'\n",
    "\n",
    "\n",
    "# def GenerateJKRegions(ra, dec, njack, maxiter=200, tol=1.0e-5):\n",
    "#     \"\"\"\n",
    "#     Generate k-means clusters from a set of data, using `kmeans_radec <https://github.com/esheldon/kmeans_radec>`_.\n",
    "#     For roughly uniform data, it generates N-clusters of roughly equal cardinality.\n",
    "#     Here, distances are computed on the surface of the unit sphere, and coordinates are given as RA/DEC.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     ra (float array)\n",
    "#         Right ascension values for each data point.\n",
    "#     dec (float array)\n",
    "#         Declination values for each data point.\n",
    "#     njack (int)\n",
    "#         Number of k-means clusters to generate, i.e. the number of JK regions.\n",
    "#     jfile (str)\n",
    "#         Output file name to save the regions.\n",
    "#     maxiter (int)\n",
    "#         Maximum number of iterations for the k-means generation, see `kmeans_radec documentation\n",
    "#         <https://github.com/esheldon/kmeans_radec>`_.\n",
    "#     tol (float)\n",
    "#         Tolerance level needed to be considered converged, see `kmeans_radec documentation\n",
    "#         <https://github.com/esheldon/kmeans_radec>`_.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     km_centers (float)\n",
    "#         Centers of selected k_means arrays\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     rd = np.zeros((len(ra), 2))\n",
    "#     rd[:, 0] = ra\n",
    "#     rd[:, 1] = dec\n",
    "\n",
    "#     km = kmeans_radec.kmeans_sample(rd, njack, maxiter=maxiter, tol=tol)\n",
    "\n",
    "#     if not km.converged:\n",
    "#         raise RuntimeError(\"k means did not converge\")\n",
    "\n",
    "#     return km.centers\n",
    "    \n",
    "# ra = np.array([], dtype=float)\n",
    "# dec = np.array([], dtype=float)\n",
    "\n",
    "# with h5py.File(red_magic_str, 'r') as f:\n",
    "#     ra = np.array(f['catalog']['redmagic']['combined_sample_fid']['ra']).copy()\n",
    "#     dec = np.array(f['catalog']['redmagic']['combined_sample_fid']['dec']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load and Setup Galaxy and Shear Data**\n",
    "\n",
    "Loads the positions and redshifts (bpz) of galaxies with robust shear estimates alongside shear estimates. Creates jackknife patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Catalog Data:\n",
      "Loading Shear Data:\n",
      "Computing Comoving Distance:\n"
     ]
    }
   ],
   "source": [
    "### Load ra, dec, redshift\n",
    "print(\"Loading Catalog Data:\")\n",
    "ra_gal = np.array(f['catalog/gold/ra'])[np.array(f['index/select'])].copy() #'index/select' ensures appropriate shear measurment\n",
    "dec_gal = np.array(f['catalog/gold/dec'])[np.array(f['index/select'])].copy()\n",
    "\n",
    "z_gal = np.array(f['catalog/bpz/unsheared/zmean_sof'])[np.array(f['index/select'])].copy()\n",
    "z_mc_gal = np.array(f['catalog/bpz/unsheared/zmc_sof'])[np.array(f['index/select'])].copy()\n",
    "\n",
    "# Remove non-applicable data points identified by negative redshift \n",
    "ind_z = np.where(z_gal > 0)[0]\n",
    "ra_gal = ra_gal[ind_z]\n",
    "dec_gal = dec_gal[ind_z]\n",
    "z_gal = z_gal[ind_z]\n",
    "z_mc_gal = z_mc_gal[ind_z]\n",
    "\n",
    "# Convert right ascension to take into account DES footprint\n",
    "ra_tem = ra_gal.copy()\n",
    "ra_tem[ra_tem > 250.] -= 360.\n",
    "ra_dec_gal = np.vstack((ra_tem, dec_gal)).T\n",
    "\n",
    "# Load shear data\n",
    "print(\"Loading Shear Data:\")\n",
    "dgamma = 2*0.01\n",
    "R = 0.5*(np.array(f['catalog/metacal/unsheared/R11'])[np.array(f['index/select'])][ind_z]+np.array(f['catalog/metacal/unsheared/R22'])[np.array(f['index/select'])][ind_z]).copy()\n",
    "Rs = 0.0120708305447 #selection response\n",
    "\n",
    "e1 = np.array(f['catalog/metacal/unsheared/e_1'])[np.array(f['index/select'])][ind_z].copy()\n",
    "e2 = np.array(f['catalog/metacal/unsheared/e_2'])[np.array(f['index/select'])][ind_z].copy()\n",
    "\n",
    "# Loading Cluster Data (Same as above):\n",
    "ra_cl = np.array(f['catalog']['redmapper']['lgt20']['ra']).copy()\n",
    "dec_cl = np.array(f['catalog']['redmapper']['lgt20']['dec']).copy()\n",
    "z_cl = np.array(f['catalog']['redmapper']['lgt20']['z']).copy()\n",
    "\n",
    "ind_z = np.where(z_cl > 0)[0]\n",
    "ra_cl = ra_cl[ind_z]\n",
    "dec_cl = dec_cl[ind_z]\n",
    "z_cl = z_cl[ind_z]\n",
    "\n",
    "ra_tem = ra_cl.copy()\n",
    "ra_tem[ra_tem > 250.] -= 360.\n",
    "ra_dec_cl = np.vstack((ra_tem, dec_cl)).T\n",
    "\n",
    "print(\"Computing Comoving Distance:\")\n",
    "dist_gal = cosmo.comoving_distance(z_gal)\n",
    "dist_mc_gal = cosmo.comoving_distance(z_mc_gal)\n",
    "dist_cl = cosmo.comoving_distance(z_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Split into 100 JK Patches**\n",
    "\n",
    "Split data for clusters and galaxies into 100 jackknife patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find jackknife patch of each galaxy\n",
    "N_GAL = len(ra_dec_gal)\n",
    "N_CL = len(ra_dec_cl)\n",
    "n_jack = 100\n",
    "\n",
    "jk_patch_gal = np.zeros(N_GAL)\n",
    "jk_patch_cl = np.zeros(N_CL)\n",
    "\n",
    "def find_nearest(coord, centers):\n",
    "    \n",
    "    return kmeans_radec.find_nearest(coord, centers)[0]\n",
    "\n",
    "\n",
    "def find_jk_gal(ra_dec, km):\n",
    "    \n",
    "    for i in range(1003):\n",
    "        progress_bar(i, 1003)\n",
    "\n",
    "        if i < 1002:\n",
    "            jk_patch_gal[i*100000:(i+1)*100000] = find_nearest(ra_dec[i*100000:(i+1)*100000], km)\n",
    "        else:\n",
    "            jk_patch_gal[i*100000:] = find_nearest(ra_dec[i*100000:], km)\n",
    "\n",
    "        progress_bar(i+1, 1003)\n",
    "    \n",
    "    return jk_patch_gal\n",
    "    \n",
    "jk_patch_gal_str = \"/global/cscratch1/sd/samgolds/DES_WL/jk_patches_gal.npy\"\n",
    "jk_patch_dm_str = \"/global/cscratch1/sd/samgolds/DES_WL/jk_patches_dm.npy\"\n",
    "center_data = np.load(\"km_centers.npy\")\n",
    "jk_patch_gal = np.load(jk_patch_gal_str)\n",
    "jk_patch_cl = np.load(jk_patch_dm_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compute Profiles (Single Profile Example)**\n",
    "\n",
    "Compute profiles for each jackknife patch separated in redshift bins. Below I currently just try and compute a single profile for a JK patch at a single redshift bin and will implement the looping over patches and redshifts once I have this figured out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_jk = SkyCoord(ra=center_data.T[0]*u.deg, dec=center_data.T[1]*u.deg) # position of the jk centers\n",
    "ang_max = 20.8 # Maximum angular scale to include: modify based on radius and JK patch size\n",
    "\n",
    "\n",
    "z_bins = [0.2, 0.4, 0.6, 0.8] # Example bin test \n",
    "\n",
    "NZBIN = len(z_bins)-1\n",
    "NBINS = 30\n",
    "\n",
    "top = np.zeros((NZBIN, NBINS))\n",
    "top_im = np.zeros((NZBIN, NBINS))\n",
    "bottom = np.zeros((NZBIN, NBINS))\n",
    "weight = np.zeros((NZBIN, NBINS))\n",
    "\n",
    "# Set jackknife index to 0 (CONVERT TO FOR-LOOP LATER)\n",
    "i = 0  \n",
    "\n",
    "# Select galaxies around JK patch\n",
    "# Select all jk patches below angular scale\n",
    "jk_dist = pos_jk[i].separation(pos_jk).degree # the distance to each JK center from each JK center\n",
    "jk_neigh_ind = np.where(jk_dist < ang_max)[0]\n",
    "\n",
    "# Select galaxy/shear JK data\n",
    "ind_jk_gal = np.in1d(jk_patch_gal, jk_neigh_ind) ### selected galaxies that have the above JK indices\n",
    "\n",
    "ra_gal_jk = ra_gal[ind_jk_gal]\n",
    "dec_gal_jk = dec_gal[ind_jk_gal]\n",
    "z_gal_jk = z_gal[ind_jk_gal]\n",
    "z_mc_gal_jk = z_mc_gal[ind_jk_gal]\n",
    "dist_gal_jk = dist_gal[ind_jk_gal]\n",
    "dist_mc_gal_jk = dist_mc_gal[ind_jk_gal]\n",
    "\n",
    "R_jk = R[ind_jk_gal]\n",
    "e1_jk = e1[ind_jk_gal]\n",
    "e2_jk = e2[ind_jk_gal]\n",
    "\n",
    "# Select cluster JK data\n",
    "ind_jk_cl = np.in1d(jk_patch_cl, jk_neigh_ind) ### selected clustrs that have the above JK indices\n",
    "\n",
    "ra_cl_jk = ra_cl[ind_jk_cl]\n",
    "dec_cl_jk = dec_cl[ind_jk_cl]\n",
    "z_cl_jk= z_cl[ind_jk_cl]\n",
    "\n",
    "# Select clusters in this redshift bin (CONVERT TO FOR-LOOP LATER)\n",
    "j = 0 \n",
    "z_min= z_bins[j]\n",
    "z_max = z_bins[j+1]\n",
    "\n",
    "z_ind_cl = np.where((z_cl_jk > z_min) & (z_cl_jk < z_max))[0]\n",
    "\n",
    "# Initialize cluster catalog\n",
    "cat_cl = treecorr.Catalog(ra=ra_cl_jk[z_ind_cl], dec=dec_cl_jk[z_ind_cl], \n",
    "                          a_units='deg', dec_units='deg')\n",
    "z_cl_zbin = np.mean(z_cl_jk[z_ind_cl])\n",
    "\n",
    "\"\"\" Removed conversion factor (10**6*h) below as result is already in Mpc\"\"\"\n",
    "dist_cl_zbin = cosmo.comoving_distance(z_cl_zbin).value  \n",
    "\n",
    "# Compute weights\n",
    "\"\"\"I'm not sure I have everything in the correct units for this\"\"\"\n",
    "wt_gal = (1./(1.663*10**12))*(1+z_cl_zbin)*dist_cl_zbin*(1.-dist_cl_zbin/dist_gal_jk.value)\n",
    "sci = (1./(1.663*10**12))*(1.+z_cl_zbin)*dist_cl_zbin*(1.-dist_cl_zbin/dist_mc_gal_jk.value)\n",
    "sci[sci<0.] = 0. ###### important\n",
    "\n",
    "\n",
    "# Select galaxies in front of cluster (with cushion)\n",
    "gal_sel = (z_gal_jk >= z_cl_zbin+0.1) \n",
    "\n",
    "# Construct galaxy catalogs\n",
    "\"\"\"Is the below equality true in WL regime? If not, how can I find gamma?\"\"\"\n",
    "gamma1 = e1_jk[gal_sel]\n",
    "gamma2 = e2_jk[gal_sel]\n",
    "\n",
    "cat_gal = treecorr.Catalog(g1=gamma1, g2=gamma2, ra=ra_gal_jk[gal_sel], dec=dec_gal_jk[gal_sel],\n",
    "                           w=wt_gal[gal_sel], ra_units='deg', dec_units='deg')\n",
    "\n",
    "cat_gal2 = treecorr.Catalog(g1=gamma1, g2=gamma2, ra=ra_gal_jk[gal_sel], dec=dec_gal_jk[gal_sel], \n",
    "                            w=(wt_gal*sci*(R_jk+Rs))[gal_sel], ra_units='deg', dec_units='deg')\n",
    "\n",
    "\n",
    "\"\"\"Is this correct? I am assuming Rmin and Rmax are in Mpc so I just put in some\"\"\"\n",
    "Rmin = 0.1\n",
    "Rmax = 2\n",
    "\n",
    "th_min = np.arctan(Rmin*10**6/dist_cl_zbin)*(180./np.pi)*60. ### minimum angular distance in arcmin\n",
    "th_max = np.arctan(Rmax*10**6/dist_cl_zbin)*(180./np.pi)*60.\n",
    "\n",
    "ng = treecorr.NGCorrelation(nbins=NBINS, min_sep=th_min, max_sep=th_max,\n",
    "                            sep_units='arcmin', verbose=2, bin_slop=0.02) \n",
    "ng2 = treecorr.NGCorrelation(nbins=NBINS, min_sep=th_min, max_sep=th_max,\n",
    "                             sep_units='arcmin', verbose=2,bin_slop=0.02)\n",
    "\n",
    "ng.process(cat_cl, cat_gal) \n",
    "ng2.process(cat_cl, cat_gal2)\n",
    "\n",
    "top[j] = ng.xi*ng.weight #### remove the denominator part so that we are only left with the numerator\n",
    "top_im[j] = ng.xi_im*ng.weight\n",
    "bottom[j] = ng2.weight #### we selected the denominator part with the different weight (R*sci*wt)\n",
    "weight[j] = ng.weight #### for calculating boost factor in the future\n",
    "\n",
    "### do it for every JK patch and combine\n",
    "\n",
    "top_total = sum(top)\n",
    "bottom_total = sum(bottom)\n",
    "\n",
    "## and then\n",
    "top_total/bottom_total\n",
    "\n",
    "### do this for 100 JK realization and calculate JK cov.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-anzestack]",
   "language": "python",
   "name": "conda-env-.conda-anzestack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
